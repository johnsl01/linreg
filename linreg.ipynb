{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linreg.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnsl01/linreg/blob/master/linreg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fldw8f0uaRR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fade1789-f059-4e3f-a48e-7294390ef84d"
      },
      "source": [
        "###############################################\n",
        "#@title                 IMPORTS               #\n",
        "###############################################\n",
        "print (\"Imports\")\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from datetime import datetime\n",
        "print (datetime.now())\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imports\n",
            "2019-09-23 16:18:33.317255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2rcNtbB00Of",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHlJ3giB07Un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# where X is a 2D np.array and theta is tuple\n",
        "# returns h_theta_x a 1D np.array\n",
        "print (\"def h_theta(X,theta)\")\n",
        "def h_theta(X,theta):\n",
        "  (_,n) = X.shape\n",
        "  t = len(theta)\n",
        "  if (t is n+1):\n",
        "    theta_np = np.array(theta[1:(t)])\n",
        "    theta0 = theta[0]\n",
        "  elif (t is n):\n",
        "    theta_np = np.array(theta[0:(t)])\n",
        "    theta0 = 0\n",
        "  print(X)\n",
        "  print(theta_np)\n",
        "\n",
        "\n",
        "    # h_theta = theta0 + theta1*X[1] + ...\n",
        "  h_theta_x = np.multiply(theta_np, X)\n",
        "  print(h_theta_x)\n",
        "    # for each row in X, h_theta[i] = X[i] * thetaN\n",
        "  h_theta_x = np.add(h_theta_x, theta0)\n",
        "  print(h_theta_x)\n",
        "    # for each element in h_theta, h_theta[i] += theta0\n",
        "  return h_theta_x\n",
        "#end h_theta\n",
        "\n",
        "# where X is a 2D np.array, and y is a 1D array and theta is a tuple\n",
        "print(\"def linearRegression(X, y, theta)\")\n",
        "def linearRegression(X, y, theta):\n",
        "  (m,_) = X.shape # extracts dimensions\n",
        "  h_theta_x = h_theta(X, theta)\n",
        "  diff = np.subtract(h_theta_x, y)\n",
        "    # for each element, h_theta[i] - y[i]\n",
        "  total_error = np.sum(np.multiply(diff, diff))\n",
        "    # squares each element in diff and sums them to find total error\n",
        "  j_theta = total_error/(2*m)\n",
        "  return j_theta\n",
        "# end linearRegression\n",
        "\n",
        "\n",
        "# assumes that X is a 2D np.array, and y and theta are 1D np.arrays\n",
        "print(\"def gradientDescent_1(X, y, theta_in, alpha)\")\n",
        "def gradientDescent_1(X, y, theta_in, alpha):\n",
        "  (m, _) = X.shape\n",
        "  h_theta_x = h_theta(X, theta_in)\n",
        "  diff = np.subtract(h_theta_x, y)\n",
        "    # for each element, h_theta[i] - y[i]\n",
        "  prodsum = np.sum(np.multiply(diff,X))\n",
        "\n",
        "  theta_out = theta_in - (alpha*prodsum)/m\n",
        "  return theta_out\n",
        "# end gradientDescent_1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"def predict(X, theta)\")\n",
        "def predict(X, theta):\n",
        "  # takes m by n matrix X as input and returns an m by 1 vector \n",
        "  # containing the predictions h_theta(x^i) for each row x^i, i=1,...,m in X\n",
        "  ##### replace the next line with your code #####\n",
        "  # print(X)\n",
        "  # print(theta)\n",
        "  # print(X.shape)\n",
        "  \n",
        "  if len(X.shape) == 1 : \n",
        "    pred = X[0]*theta[0] + X[1]*theta[1]   \n",
        "  else : \n",
        "    pred = X[:,0]*theta[0] + X[:,1]*theta[1] \n",
        "    \n",
        "  # print(pred)\n",
        "  return pred\n",
        "# end predict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"def computeCost(X, y, theta)\")\n",
        "def computeCost(X, y, theta):\n",
        "  # function calculates the cost J(theta) and return its value\n",
        "  ##### replace the next line with your code #####\n",
        "  print (\"Compute cost #1 : \" , X.shape, y.shape, theta.shape)\n",
        "  costpred = predict (X,theta)\n",
        "  print (\"Compute Cost #2 :\", costpred.shape)\n",
        "  costbase = costpred - y\n",
        "  print (\"Compute Cost #3 :\", costbase.shape)\n",
        "  costsq = costbase * costbase\n",
        "  print (\"Compute Cost #4 :\", costsq.shape)\n",
        "  cost = costsq.sum()\n",
        "  print (\"Compute Cost #5 :\", cost)\n",
        "  # cost = 0\n",
        "  return cost\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"def computeGradient(X, y, theta)\")\n",
        "def computeGradient(X, y, theta):\n",
        "  # function calulate the gradient of J(theta) and returns its value\n",
        "  ##### replace the next line with your code #####\n",
        "  n=len(theta)\n",
        "  grad = np.zeros(n)\n",
        "  return grad\n",
        "\n",
        "\n",
        "print (datetime.now())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vjjkR9X08NL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPkP3zRP09AL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a3ad37f7-25a8-4d94-9db7-7464020e6012"
      },
      "source": [
        "\n",
        "print(\"def gradientDescent(X, y, numparams)\")\n",
        "def gradientDescent(X, y, numparams):\n",
        "  # iteratively update parameter vector theta\n",
        "  # -- you should not modify this function\n",
        "\n",
        "  # initialize variables for learning rate and iterations\n",
        "  alpha = 0.02\n",
        "  iters = 5000\n",
        "  cost = np.zeros(iters)\n",
        "  theta= np.zeros(numparams)\n",
        "\n",
        "  for i in range(iters):\n",
        "    theta = theta - alpha * computeGradient(X,y,theta)\n",
        "    cost[i] = computeCost(X, y, theta)\n",
        "\n",
        "  return theta, cost\n",
        "\n",
        "\n",
        "\n",
        "print(\"def normaliseData(x)\")\n",
        "def normaliseData(x):\n",
        "  # rescale data to lie between 0 and 1\n",
        "  scale = x.max(axis=0)\n",
        "  return (x/scale, scale)\n",
        "\n",
        "\n",
        "\n",
        "print(\"def splitData(X, y)\")\n",
        "def splitData(X, y):\n",
        "  # split data into training and test parts\n",
        "  # ... for now, we use all of the data for training and testing\n",
        "  Xtrain=X; ytrain=y; Xtest=X; ytest=y\n",
        "  return (Xtrain, ytrain, Xtest, ytest)\n",
        "\n",
        "print (datetime.now())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def gradientDescent(X, y, numparams)\n",
            "def normaliseData(x)\n",
            "def splitData(X, y)\n",
            "2019-09-23 16:19:00.532776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqEOQP5Z0-J-",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH7808b81TMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f06749b4-790b-430e-f808-37076291c532"
      },
      "source": [
        "print (\"def main()\")\n",
        "def main():\n",
        "  # load the data\n",
        "  # \"https://raw.githubusercontent.com/johnsl01/Titanic_Python/master/titanic_known.csv\"\n",
        "  data=np.loadtxt('https://raw.githubusercontent.com/johnsl01/linreg/master/stockprices.csv',usecols=(1,2))\n",
        "  X=data[:,0]\n",
        "  y=data[:,1]\n",
        "\n",
        "  # plot the data so we can see how it looks\n",
        "  # (output is in file graph.png)\n",
        "  fig, ax = plt.subplots(figsize=(12, 8))\n",
        "  ax.scatter(X, y, label='Data')\n",
        "  ax.set_xlabel('Amazon')\n",
        "  ax.set_ylabel('Google')\n",
        "  ax.set_title('Google stock price vs Amazon')\n",
        "  fig.savefig('graph.png')\n",
        "\n",
        "  # split the data into training and test parts\n",
        "  (Xtrain, ytrain, Xtest, ytest)=splitData(X,y)\n",
        "\n",
        "  # add a column of ones to input data\n",
        "  m=len(y) # m is number of training data points\n",
        "  Xtrain = np.column_stack((np.ones((m, 1)), Xtrain))\n",
        "  (m,n)=Xtrain.shape # m is number of data points, n number of features\n",
        "\n",
        "  # rescale training data to lie between 0 and 1\n",
        "  (Xt,Xscale) = normaliseData(Xtrain)\n",
        "  (yt,yscale) = normaliseData(ytrain)\n",
        "\n",
        "  # calculate the prediction\n",
        "  print('testing the prediction function ...')\n",
        "  theta=(1,2)\n",
        "  print('when x=[1,1] and theta is [1,2]) cost = ',predict(np.ones(n),theta))\n",
        "  print('approx expected prediction is 3')\n",
        "  print('when x=[[1,1],[5,5]] and theta is [1,2]) cost = ',predict(np.array([[1,1],[5,5]]),theta))\n",
        "  print('approx expected prediction is [3,11]')\n",
        "  input('Press Enter to continue...')\n",
        "\n",
        "  # calculate the cost when theta iz zero\n",
        "  print('testing the cost function ...')\n",
        "  theta=np.zeros(n)\n",
        "  print('when theta is zero cost = ',computeCost(Xt,yt,theta))\n",
        "  print('approx expected cost value is 0.318')\n",
        "  input('Press Enter to continue...')\n",
        "\n",
        "  # calculate the gradient when theta is zero\n",
        "  print('testing the gradient function ...')\n",
        "  print('when theta is zero gradient = ',computeGradient(Xt,yt,theta))\n",
        "  print('approx expected gradient value is [-0.79,-0.59]')\n",
        "  input('Press Enter to continue...')\n",
        "\n",
        "  # perform gradient descent to \"fit\" the model parameters\n",
        "  print('running gradient descent ...')\n",
        "  theta, cost = gradientDescent(Xt, yt, n)\n",
        "  print('after running gradientDescent() theta=',theta)\n",
        "  print('approx expected value is [0.34, 0.61]')\n",
        "\n",
        "  # plot some predictions\n",
        "  Xpred = np.linspace(X.min(), X.max(), 100)\n",
        "  Xpred = np.column_stack((np.ones((100, 1)), Xpred))\n",
        "  ypred = predict(Xpred/Xscale, theta)*yscale\n",
        "  fig, ax = plt.subplots(figsize=(12, 8))\n",
        "  ax.scatter(Xtest, ytest, color='b', label='Test Data')\n",
        "  ax.plot(Xpred[:,1], ypred, 'r', label='Prediction')\n",
        "  ax.set_xlabel('Amazon')\n",
        "  ax.set_ylabel('Google')\n",
        "  ax.legend(loc=2)\n",
        "  fig.savefig('pred.png')\n",
        "\n",
        "  # and plot how the cost varies as the gradient descent proceeds\n",
        "  fig2, ax2 = plt.subplots(figsize=(12, 8))\n",
        "  ax2.semilogy(cost,'r')\n",
        "  ax2.set_xlabel('iteration')\n",
        "  ax2.set_ylabel('cost')\n",
        "  fig2.savefig('cost.png')\n",
        "  \n",
        "  # plot the cost function\n",
        "  fig3 = plt.figure()\n",
        "  ax3 = fig3.add_subplot(1, 1, 1, projection='3d')\n",
        "  n=100\n",
        "  theta0, theta1 = np.meshgrid(np.linspace(-3, 3, n), np.linspace(-3, 2, n))\n",
        "  cost = np.empty((n,n))\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      cost[i,j] = computeCost(Xt,yt,(theta0[i,j],theta1[i,j]))\n",
        "  ax3.plot_surface(theta0,theta1,cost)\n",
        "  ax3.set_xlabel('theta0')\n",
        "  ax3.set_ylabel('theta1')\n",
        "  ax3.set_zlabel('J(theta)')\n",
        "  fig3.savefig('J.png')\n",
        "  \n",
        "  \n",
        "print (datetime.now())\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def main()\n",
            "2019-09-23 16:19:05.733429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNsoCBRt1bha",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiLpSKwE1ckc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "e37a3733-c8e4-4d3a-ed50-9e3768ac041d"
      },
      "source": [
        "print (datetime.now())\n",
        "\n",
        "main()\n",
        "\n",
        "print (datetime.now())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-23 17:03:56.417955\n",
            "testing the prediction function ...\n",
            "when x=[1,1] and theta is [1,2]) cost =  3.0\n",
            "approx expected prediction is 3\n",
            "when x=[[1,1],[5,5]] and theta is [1,2]) cost =  [ 3 15]\n",
            "approx expected prediction is [3,11]\n",
            "Press Enter to continue...\n",
            "testing the cost function ...\n",
            "Compute cost #1 :  (248, 2) (248,) (2,)\n",
            "Compute Cost #2 : (248,)\n",
            "Compute Cost #3 : (248,)\n",
            "Compute Cost #4 : (248,)\n",
            "Compute Cost #5 : 158.06347382089487\n",
            "when theta is zero cost =  158.06347382089487\n",
            "approx expected cost value is 0.318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpP7InSLDUl4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjI-DG_EDV76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test section \n",
        "# assume all defs are in place \n",
        "# but main hasn't run\n",
        "\n",
        "test_array = np.array([[1,3],[5,7],[11,13]])\n",
        "print ( test_array.shape )\n",
        "test_theta = np.array([[1,2,3]])\n",
        "print ( test_theta.shape )\n",
        "\n",
        "test_predict = predict (test_array, test_theta)\n",
        "print(test_predict)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNFAS80nGUHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (test_array)\n",
        "print (test_array * 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLVjtO73Gekf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (test_array + test_array)\n",
        "print (test_array[0,:])\n",
        "print (test_array[1,:])\n",
        "print (test_array[2,:])\n",
        "print (test_array[:,0])\n",
        "print (test_array[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOFsB7PkWMgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_1 = np.zeros((test_array.shape[0],test_array.shape[1]))\n",
        "print (predict_1.shape)\n",
        "print (predict_1)\n",
        "\n",
        "print (predict_1[0,:])\n",
        "print (predict_1[1,:])\n",
        "print (predict_1[2,:])\n",
        "print (predict_1[:,0])\n",
        "print (predict_1[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7KElaA90mQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testnum = \"Case #1\"\n",
        "myX = np.array([1,1])\n",
        "mytheta = (1,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_2lfFOB9p-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testnum = \"Case #2\"\n",
        "myX = np.array([[1,1],[5,5]])\n",
        "mytheta = (1,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NEBjvfq-Z4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "13f59220-5adf-4384-e81b-1b07445e8871"
      },
      "source": [
        "print (testnum)\n",
        "print (datetime.now())\n",
        "print (\"Shape of myX : \", myX.shape)\n",
        "print (\"Type of myX.shape : \" , type (myX.shape))\n",
        "print (\"Len of myX.shape : \", len(myX.shape))\n",
        "if len(myX.shape) == 1 : \n",
        "  print (\"myX col 0 : \", myX[0])\n",
        "  print (\"myX col 1 : \", myX[1])\n",
        "else : \n",
        "  print (\"myX col 0 : \", myX[:,0])\n",
        "  print (\"myX col 1 : \", myX[:,1])\n",
        "print (mytheta[0])\n",
        "print (mytheta[1])\n",
        "mypredict_1 = predict(myX,mytheta)\n",
        "print (mypredict_1.shape)\n",
        "print (mypredict_1)\n",
        "print (datetime.now())"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Case #2\n",
            "2019-09-23 16:48:02.649345\n",
            "Shape of myX :  (2, 2)\n",
            "Type of myX.shape :  <class 'tuple'>\n",
            "Len of myX.shape :  2\n",
            "myX col 0 :  [1 5]\n",
            "myX col 1 :  [1 5]\n",
            "1\n",
            "2\n",
            "(2,)\n",
            "[ 3 15]\n",
            "2019-09-23 16:48:02.659455\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}